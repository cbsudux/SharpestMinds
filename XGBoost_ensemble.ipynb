{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost script --> WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "100%|██████████| 794/794 [00:07<00:00, 112.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "label_map = {   \"Black-grass\"               :0,\n",
    "                \"Charlock\"                  :1,\n",
    "                \"Cleavers\"                  :2,\n",
    "                \"Common Chickweed\"          :3,\n",
    "                \"Common wheat\"              :4,\n",
    "                \"Fat Hen\"                   :5,\n",
    "                \"Loose Silky-bent\"          :6,\n",
    "                \"Maize\"                     :7,\n",
    "                \"Scentless Mayweed\"         :8,\n",
    "                \"Shepherds Purse\"           :9,\n",
    "                \"Small-flowered Cranesbill\" :10,\n",
    "                \"Sugar beet\"                :11}\n",
    "\n",
    "dim = 256\n",
    "x_test = []\n",
    "df_test = pd.read_csv('/input/plant_seedlings_classification/sample_submission.csv')\n",
    "\n",
    "# Prepare testing data\n",
    "for f, species in tqdm(df_test.values, miniters=100):\n",
    "    img = cv2.imread('/input/plant_seedlings_classification/test/{}'.format(f))\n",
    "    x_test.append(cv2.resize(img, (dim, dim)))\n",
    "\n",
    "x_test = np.array(x_test, np.float32)\n",
    "print(x_test.shape)\n",
    "x_test = x_test /255.0\n",
    "\n",
    "\n",
    "# Preparing training data for prediction\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "dirs = os.listdir(\"/input/plant_seedlings_classification/train/\")\n",
    "for k in tqdm(range(len(dirs))):    # Directory\n",
    "    files = os.listdir(\"/input/plant_seedlings_classification/train/{}\".format(dirs[k]))\n",
    "    for f in range(len(files)):     # Files\n",
    "        img = cv2.imread('/input/plant_seedlings_classification/train/{}/{}'.format(dirs[k], files[f]))\n",
    "        targets = np.zeros(12)\n",
    "        targets[label_map[dirs[k]]] = 1 \n",
    "        x_train.append(cv2.resize(img, (dim, dim)))\n",
    "        y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32)\n",
    "\n",
    "x_train = x_train/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all models\n",
    "base_model = Xception(input_shape=(dim, dim, 3), include_top=False, weights=None, pooling='avg') # Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model_x = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "base_model = InceptionV3(input_shape=(dim, dim, 3), include_top=False, weights=None, pooling='avg') # Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model_i = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "base_model = ResNet50(input_shape=(dim, dim, 3), include_top=False, weights=None, pooling='avg') # Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model_r = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "base_model = InceptionResNetV2(input_shape=(dim, dim, 3), include_top=False, weights=None, pooling='avg') # Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model_ir = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 88s 19ms/step\n",
      "4750/4750 [==============================] - 59s 12ms/step\n",
      "4750/4750 [==============================] - 105s 22ms/step\n",
      "4750/4750 [==============================] - 78s 16ms/step\n",
      "794/794 [==============================] - 14s 18ms/step\n",
      "794/794 [==============================] - 10s 13ms/step\n",
      "794/794 [==============================] - 17s 22ms/step\n",
      "794/794 [==============================] - 13s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "model_x.load_weights('/input/weights_x.h5')\n",
    "model_i.load_weights('/input/weights_i.h5')\n",
    "model_r.load_weights('/input/weights_r.h5')\n",
    "model_ir.load_weights('/input/weights_ir.h5')\n",
    "\n",
    "def predict(model,x):\n",
    "    predictions = model.predict(x, verbose = 1)\n",
    "    return predictions\n",
    "\n",
    "pred_train_x = predict(model_x , x_train)\n",
    "pred_train_i = predict(model_i , x_train)\n",
    "pred_train_ir = predict(model_ir, x_train)\n",
    "pred_train_r = predict(model_r, x_train)\n",
    "\n",
    "pred_test_x = predict(model_x , x_test)\n",
    "pred_test_i = predict(model_i , x_test)\n",
    "pred_test_ir = predict(model_ir, x_test)\n",
    "pred_test_r = predict(model_r, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new features\n",
    "Y = (y_train * range(12)).sum(axis=1)\n",
    "X = np.hstack([pred_train_x, pred_train_i,pred_train_ir, pred_train_r])\n",
    "T = np.hstack([pred_test_x, pred_test_i, pred_test_ir,pred_test_r])\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X, Y)\n",
    "\n",
    "# prefict on test set\n",
    "y_pred = model.predict(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "encoded = to_categorical(y_pred)\n",
    "\n",
    "# funciton for submittable format\n",
    "def get_submit(p_test):\n",
    "    preds = []\n",
    "    for i in range(len(p_test)):\n",
    "        pos = np.argmax(p_test[i])\n",
    "        preds.append(list(label_map.keys())[list(label_map.values()).index(pos)])\n",
    "    return preds\n",
    "\n",
    "# get submittable format\n",
    "preds = get_submit(encoded)\n",
    "\n",
    "df_test['species'] = preds\n",
    "df_test.to_csv('/output/submission_111.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
