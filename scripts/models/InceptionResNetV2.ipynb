{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os, cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:56<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4750, 256, 256, 3)\n",
      "(4750, 12)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "label_map = {   \"Black-grass\"               :0,\n",
    "                \"Charlock\"                  :1,\n",
    "                \"Cleavers\"                  :2,\n",
    "                \"Common Chickweed\"          :3,\n",
    "                \"Common wheat\"              :4,\n",
    "                \"Fat Hen\"                   :5,\n",
    "                \"Loose Silky-bent\"          :6,\n",
    "                \"Maize\"                     :7,\n",
    "                \"Scentless Mayweed\"         :8,\n",
    "                \"Shepherds Purse\"           :9,\n",
    "                \"Small-flowered Cranesbill\" :10,\n",
    "                \"Sugar beet\"                :11}\n",
    "\n",
    "dim = 256\n",
    "\n",
    "# Preparing training data\n",
    "dirs = os.listdir(\"/input/plant_seedlings_classification/train/\")\n",
    "for k in tqdm(range(len(dirs))):    # Directory\n",
    "    files = os.listdir(\"/input/plant_seedlings_classification/train/{}\".format(dirs[k]))\n",
    "    for f in range(len(files)):     # Files\n",
    "        img = cv2.imread('/input/plant_seedlings_classification/train/{}/{}'.format(dirs[k], files[f]))\n",
    "        targets = np.zeros(12)\n",
    "        targets[label_map[dirs[k]]] = 1 \n",
    "        x_train.append(cv2.resize(img, (dim, dim)))\n",
    "        y_train.append(targets)\n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.float32)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.01, random_state=42)\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.16, random_state=42) # Want a balanced split for all the classes\n",
    "for train_index, test_index in sss.split(x_train, y_train):\n",
    "    print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n",
    "    x_train, x_valid = x_train[train_index], x_train[test_index]\n",
    "    y_train, y_valid = y_train[train_index], y_train[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator( horizontal_flip=True, \n",
    "                              vertical_flip=True,\n",
    "                            rescale = 1./255)\n",
    "                                      \n",
    "weights = os.path.join('', '/output/weights.h5')\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "callbacks = [ EarlyStopping(monitor='val_loss', patience=5, verbose=0), \n",
    "              ModelCheckpoint(weights, monitor='val_loss', save_best_only=True, verbose=0),\n",
    "              ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)]\n",
    "\n",
    "base_model = InceptionResNetV2(input_shape=(dim, dim, 3), include_top=False, weights='imagenet', pooling='avg') # Average pooling reduces output dimensions\n",
    "x = base_model.output\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(12, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=learning_rate), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "125/124 [==============================] - 415s 3s/step - loss: 0.9355 - acc: 0.6990 - val_loss: 3.7049 - val_acc: 0.3105\n",
      "Epoch 2/21\n",
      "125/124 [==============================] - 295s 2s/step - loss: 0.4749 - acc: 0.8487 - val_loss: 5.0824 - val_acc: 0.4013\n",
      "Epoch 3/21\n",
      "125/124 [==============================] - 298s 2s/step - loss: 0.3616 - acc: 0.8774 - val_loss: 1.5777 - val_acc: 0.6974\n",
      "Epoch 4/21\n",
      "125/124 [==============================] - 297s 2s/step - loss: 0.3159 - acc: 0.8973 - val_loss: 0.8135 - val_acc: 0.7816\n",
      "Epoch 5/21\n",
      "125/124 [==============================] - 297s 2s/step - loss: 0.2571 - acc: 0.9163 - val_loss: 0.2739 - val_acc: 0.9105\n",
      "Epoch 6/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.2458 - acc: 0.9199 - val_loss: 2.2538 - val_acc: 0.6684\n",
      "Epoch 7/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.2378 - acc: 0.9216 - val_loss: 0.3852 - val_acc: 0.9066\n",
      "Epoch 8/21\n",
      "125/124 [==============================] - 296s 2s/step - loss: 0.1634 - acc: 0.9464 - val_loss: 0.7740 - val_acc: 0.8421\n",
      "Epoch 9/21\n",
      "125/124 [==============================] - 297s 2s/step - loss: 0.1178 - acc: 0.9611 - val_loss: 0.1080 - val_acc: 0.9618\n",
      "Epoch 10/21\n",
      "125/124 [==============================] - 297s 2s/step - loss: 0.0760 - acc: 0.9741 - val_loss: 0.0872 - val_acc: 0.9658\n",
      "Epoch 11/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0633 - acc: 0.9788 - val_loss: 0.0919 - val_acc: 0.9632\n",
      "Epoch 12/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0580 - acc: 0.9800 - val_loss: 0.0921 - val_acc: 0.9632\n",
      "Epoch 13/21\n",
      "125/124 [==============================] - 297s 2s/step - loss: 0.0501 - acc: 0.9840 - val_loss: 0.0798 - val_acc: 0.9684\n",
      "Epoch 14/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0450 - acc: 0.9861 - val_loss: 0.0911 - val_acc: 0.9724\n",
      "Epoch 15/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0389 - acc: 0.9863 - val_loss: 0.0997 - val_acc: 0.9711\n",
      "Epoch 16/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0303 - acc: 0.9915 - val_loss: 0.0986 - val_acc: 0.9684\n",
      "Epoch 17/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0315 - acc: 0.9902 - val_loss: 0.0882 - val_acc: 0.9697\n",
      "Epoch 18/21\n",
      "125/124 [==============================] - 297s 2s/step - loss: 0.0290 - acc: 0.9914 - val_loss: 0.0655 - val_acc: 0.9750\n",
      "Epoch 19/21\n",
      "125/124 [==============================] - 295s 2s/step - loss: 0.0275 - acc: 0.9914 - val_loss: 0.0871 - val_acc: 0.9711\n",
      "Epoch 20/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0252 - acc: 0.9929 - val_loss: 0.0813 - val_acc: 0.9724\n",
      "Epoch 21/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0742 - val_acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5d558eeb8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training whole convnet\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size, \n",
    "                    validation_data=datagen.flow(x_valid, y_valid, batch_size=batch_size), \n",
    "                    validation_steps=len(x_valid)/batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=21, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0204 - acc: 0.9945 - val_loss: 0.0844 - val_acc: 0.9750\n",
      "Epoch 2/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0247 - acc: 0.9922 - val_loss: 0.0746 - val_acc: 0.9763\n",
      "Epoch 3/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0225 - acc: 0.9934 - val_loss: 0.0658 - val_acc: 0.9737\n",
      "Epoch 4/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0219 - acc: 0.9945 - val_loss: 0.0835 - val_acc: 0.9711\n",
      "Epoch 5/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0757 - val_acc: 0.9711\n",
      "Epoch 6/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0235 - acc: 0.9927 - val_loss: 0.0752 - val_acc: 0.9750\n",
      "Epoch 7/21\n",
      "125/124 [==============================] - 295s 2s/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0782 - val_acc: 0.9697\n",
      "Epoch 8/21\n",
      "125/124 [==============================] - 294s 2s/step - loss: 0.0219 - acc: 0.9940 - val_loss: 0.0718 - val_acc: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5a436b860>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=len(x_train)/batch_size, \n",
    "                    validation_data=datagen.flow(x_valid, y_valid, batch_size=batch_size), \n",
    "                    validation_steps=len(x_valid)/batch_size,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=21, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 794/794 [00:05<00:00, 145.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# ------ TESTING ------\n",
    "x_test = []\n",
    "df_test = pd.read_csv('/input/plant_seedlings_classification/sample_submission.csv')\n",
    "\n",
    "for f, species in tqdm(df_test.values, miniters=100):\n",
    "    img = cv2.imread('/input/plant_seedlings_classification/test/{}'.format(f))\n",
    "    x_test.append(cv2.resize(img, (dim, dim)))\n",
    "\n",
    "x_test = np.array(x_test, np.float32)\n",
    "print(x_test.shape)\n",
    "\n",
    "x_test = x_test /255.0\n",
    "\n",
    "if os.path.isfile(weights):\n",
    "    model.load_weights(weights)\n",
    "\n",
    "p_test = model.predict(x_test, verbose = 1)\n",
    "\n",
    "preds = []\n",
    "for i in range(len(p_test)):\n",
    "    pos = np.argmax(p_test[i])\n",
    "    preds.append(list(label_map.keys())[list(label_map.values()).index(pos)])\n",
    "\n",
    "df_test['species'] = preds\n",
    "df_test.to_csv('/output/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
